{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Create some essential folder\n",
        "!mkdir auth\n",
        "!mkdir datasets"
      ],
      "metadata": {
        "id": "EQOq71xmuW1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLuwCNUmuFqP"
      },
      "outputs": [],
      "source": [
        "# Download data from Google Storage\n",
        "\n",
        "import pathlib\n",
        "from google.cloud import storage\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "class GCSClient:\n",
        "    def __init__(self, gcs_authen_file_path: str):\n",
        "        \"\"\"\n",
        "            Initial the Google cloud client with credential\n",
        "        Args:\n",
        "            gcs_authen_file_path: a file name in ./auth folder\n",
        "            abstract_logger: the logger\n",
        "        \"\"\"\n",
        "        self.__gcs_credentials = service_account.Credentials.from_service_account_file(\n",
        "            gcs_authen_file_path,\n",
        "            scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
        "        )\n",
        "        self.storage_client = storage.Client(\n",
        "            credentials=self.__gcs_credentials,\n",
        "            project=self.__gcs_credentials.project_id,\n",
        "        )\n",
        "\n",
        "    def download_gcs_file(self, bucket_name: str, source_blob_name: str, dest_file_path: str):\n",
        "        \"\"\"\n",
        "            Install GCS file blob to local folder file\n",
        "        Args:\n",
        "            bucket_name: The ID of GCS bucket. Ex: \"your-bucket-name\"\n",
        "            source_blob_name: The ID of GCS object which is file. Ex: \"storage-object-name\"\n",
        "            dest_file_path: The path to which the local file should be downloaded. Ex: \"local/path/to/file\"\n",
        "        \"\"\"\n",
        "        try:\n",
        "            bucket = self.storage_client.bucket(bucket_name)\n",
        "\n",
        "            # Construct a client side representation of a blob.\n",
        "            # Note `Bucket.blob` differs from `Bucket.get_blob` as it doesn't retrieve\n",
        "            # any content from Google Cloud Storage. As we don't need additional data,\n",
        "            # using `Bucket.blob` is preferred here.\n",
        "            blob = bucket.blob(source_blob_name)\n",
        "            blob.download_to_filename(dest_file_path)\n",
        "            print(\n",
        "                \"Downloaded storage object {} from bucket {} to local file {}.\".format(\n",
        "                    source_blob_name, bucket_name, dest_file_path\n",
        "                )\n",
        "            )\n",
        "        except Exception as py_exc:\n",
        "            print(f\"Download from GCS to local file system - {str(py_exc)}\")\n",
        "\n",
        "    def download_gcs_folder(self, bucket_name: str, directory_of_blob: str, destination_folder_path: str):\n",
        "        \"\"\"\n",
        "            Download GCS folder blob to local folder path\n",
        "        Args:\n",
        "            bucket_name: The ID of GCS bucket name.Ex: \"your-bucket-name\"\n",
        "            directory_of_blob: The ID of GCS object which is folder. Ex: \"storage\"\n",
        "            destination_folder_path: The name of the destination project\n",
        "        \"\"\"\n",
        "        try:\n",
        "            blobs_in_bucket = self.storage_client.list_blobs(bucket_name, prefix=directory_of_blob)\n",
        "            for blob in blobs_in_bucket:\n",
        "                local_filename = (pathlib.Path(destination_folder_path) / blob.name.split(\"/\")[-1]).resolve()\n",
        "                blob.download_to_filename(filename=str(local_filename))\n",
        "                print(\n",
        "                    \"Downloaded storage object {}/* from bucket {} to local file {}.\".format(\n",
        "                        directory_of_blob, bucket_name, local_filename\n",
        "                    )\n",
        "                )\n",
        "        except Exception as py_exc:\n",
        "            print(f\"Download folder blob from GCS - Failed: {py_exc}\")\n",
        "\n",
        "    def upload_gcs_file(self, bucket_name: str, source_file_path: str, dest_blob_path: str):\n",
        "        \"\"\"\n",
        "            Upload a file to GCS bucket\n",
        "        Args:\n",
        "            bucket_name: The ID of GCS bucket name. Ex: \"your-bucket-name\"\n",
        "            source_file_path: The file path of source. Ex: \"local/path/to/file\"\n",
        "            dest_bucket_file: The ID of GCS object which is file uploaded. Ex: \"storage\"\n",
        "        \"\"\"\n",
        "        try:\n",
        "            bucket = self.storage_client.bucket(bucket_name)\n",
        "            bucket.blob(dest_blob_path).upload_from_filename(source_file_path)\n",
        "            print(f\"File {source_file_path} uploaded to {dest_blob_path}.\")\n",
        "        except Exception as py_exc:\n",
        "            print(f\"Upload file to GCS blob - Failed: {py_exc}\")\n",
        "\n",
        "    def upload_gcs_folder(self, bucket_name: str, source_folder_path: str, dest_folder_bucket: str):\n",
        "        \"\"\"\n",
        "            Upload a folder has only files to GCS bucket\n",
        "        Args:\n",
        "            bucket_name: The ID of GCS bucket name. Ex: \"your-bucket-name\"\n",
        "            source_folder_path:  The folder path of source\n",
        "            dest_folder_bucket: The ID of GCS object which is folder path. Ex \"your-bucket-name/path/to/GCS/folder\"\n",
        "        \"\"\"\n",
        "        try:\n",
        "            bucket = self.storage_client.bucket(bucket_name)\n",
        "            dir_recursive_paths = pathlib.Path(source_folder_path)\n",
        "            for path in dir_recursive_paths.iterdir():\n",
        "                if path.is_file():\n",
        "                    bucket.blob(dest_folder_bucket).upload_from_filename(dest_folder_bucket)\n",
        "                    print(f\"File {source_folder_path} uploaded to {dest_folder_bucket}\")\n",
        "        except Exception as py_exc:\n",
        "            print(f\"Upload the folder of file system to GCS - Failed: {py_exc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset from GCS\n",
        "pwd = pathlib.Path()\n",
        "gcs_authen_path = pwd / \"auth\" / \"kiotviet-connect-sr.json\"\n",
        "diginetica_fs_path = pwd / \"dataset-train-diginetica.zip\"\n",
        "yoochoose_fs_path = pwd / \"yoochoose-data.7z\"\n",
        "\n",
        "gcsClient = GCSClient(gcs_authen_file_path=gcs_authen_path)\n",
        "\n",
        "# Download diginetica dataset\n",
        "gcsClient.download_gcs_file(\n",
        "    bucket_name=\"bi_recommendation_hub_storage\",\n",
        "    source_blob_name=\"recommend/session-based/dataset-train-diginetica.zip\",\n",
        "    dest_file_path=diginetica_fs_path\n",
        ")\n",
        "\n",
        "# Download yoochoose\n",
        "gcsClient.download_gcs_file(\n",
        "    bucket_name=\"bi_recommendation_hub_storage\",\n",
        "    source_blob_name=\"recommend/session-based/yoochoose-data.7z\",\n",
        "    dest_file_path=yoochoose_fs_path\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxdmDY_MuQgu",
        "outputId": "d9d8d34b-3727-46eb-8940-3d17f72d62a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded storage object recommend/session-based/dataset-train-diginetica.zip from bucket bi_recommendation_hub_storage to local file dataset-train-diginetica.zip.\n",
            "Downloaded storage object recommend/session-based/yoochoose-data.7z from bucket bi_recommendation_hub_storage to local file yoochoose-data.7z.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "mkdir /content/datasets/diginetica\n",
        "unzip /content/dataset-train-diginetica.zip -d /content/datasets/diginetica\n",
        "echo \"======================\"\n",
        "mkdir /content/datasets/yoochoose\n",
        "7z x /content/yoochoose-data.7z -o/content/datasets/yoochoose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WOzdNE2uSmK",
        "outputId": "f42901e2-dd8d-4baa-8e8b-32fe485ab764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/dataset-train-diginetica.zip\n",
            "  inflating: /content/datasets/diginetica/train-clicks.csv  \n",
            "  inflating: /content/datasets/diginetica/train-purchases.csv  \n",
            "  inflating: /content/datasets/diginetica/train-item-views.csv  \n",
            "  inflating: /content/datasets/diginetica/train-queries.csv  \n",
            "  inflating: /content/datasets/diginetica/products.csv  \n",
            "  inflating: /content/datasets/diginetica/product-categories.csv  \n",
            "======================\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 287211932 bytes (274 MiB)\n",
            "\n",
            "Extracting archive: /content/yoochoose-data.7z\n",
            "--\n",
            "Path = /content/yoochoose-data.7z\n",
            "Type = 7z\n",
            "Physical Size = 287211932\n",
            "Headers Size = 255\n",
            "Method = LZMA:24\n",
            "Solid = +\n",
            "Blocks = 2\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  0% - yoochoose-buys.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% - yoochoose-buys.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% - yoochoose-buys.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 3\b\b\b\b\b\b      \b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Files: 4\n",
            "Size:       1914111754\n",
            "Compressed: 287211932\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1. Dataset\n",
        "yoochoose là tập dữ liệu được cung cấp từ cuộc thi RecSys Challange 2015. Dữ liệu bao gồm tập hợp các thông tin về các click event trong từng session tương ứng. Trong các events sẽ bao gồm buy event giúp xác định các sự kiện mua hàng. Mục tiêu là dự báo khách hàng có khả năng mua hàng sắp tới không và nếu mua hàng thì mua sản phẩm nào?\n",
        "\n",
        "Bộ dữ liệu bao gồm 3 files chính:\n",
        "\n",
        "Các files huấn luyện:\n",
        "\n",
        "1 . yoochoose-clicks.dat: Dữ liệu về các click events. Mỗi một dòng bao gồm các trường sau đây:\n",
        "\n",
        "Session ID: Id của session. Trong một session có thể có 1 hoặc nhiều lượt clicks.\n",
        "Timestamp: Thời điểm diễn ra click.\n",
        "Item ID: Id dùng để xác định item.\n",
        "Category: Nhóm category của item.\n",
        "2 . yoochoose-buys.dat: Dữ liệu về buy events. Mỗi một dòng bao gồm các trường sau đây:\n",
        "\n",
        "Session ID: Id của session. Trong một session có thể có 1 hoặc nhiều lượt mua sắm.\n",
        "Timestamp: Thời điểm diễn ra hành vi mua sắm.\n",
        "Item ID: Id của item.\n",
        "Price: Gía của sản phẩm.\n",
        "Quantity: Số lượng sản phẩm được mua.\n",
        "Do các trong các session sẽ một số session có các event buying nên số lượng các session trong file yoochoose-buys.dat nhiều hơn so với yoochoose-clicks.dat và mọi session trong file yoochoose-buys.dat sẽ chứa trong file yoochoose-clicks.dat. Một session có thể rất ngắn (vài phút) hoặc rất dài (vài giờ) và theo đó số lượng event cũng tương ứng ít hoặc nhiều tùy vào hoạt động của user.\n",
        "\n",
        "File kiểm tra:\n",
        "\n",
        "3 . yoochoose-test.dat: Cấu trúc tương tự như file yoochoose-clicks.dat của huấn luyện. Bao gồm các trường: Session ID, Timestamp, Item ID, Category. Mục tiêu của chúng ta là cần dự báo xem trong các session của tập test có event buying hay không và nếu có thì list các Item ID được mua là gì?\n",
        "\n"
      ],
      "metadata": {
        "id": "xpOBk3LUwbcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1.1. Khởi tạo dữ liệu"
      ],
      "metadata": {
        "id": "Xl_UPNcqwSt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "filepath = '/content/datasets/yoochoose/yoochoose-clicks.dat'\n",
        "dataset = pd.read_csv(filepath, names = ['SessionId', 'DateTime', 'ItemId', 'Category'])\n",
        "dataset['DateTime'] = dataset['DateTime'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ'))\n",
        "dataset['Timestamp'] = dataset['DateTime'].apply(lambda x: x.strftime('%s.%f'))\n",
        "dataset = dataset.sort_values(by = ['SessionId', 'DateTime'], ascending = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUDMOa_PubbB",
        "outputId": "27f4cb30-fe95-4868-e888-90b7e57a81e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Thống kê số lượt xuất hiện và lọc ra các ItemId có trên 5 lượt xuất hiện\n",
        "df_item_count = dataset[['ItemId', 'SessionId']].groupby('ItemId').count().sort_values(by = 'SessionId', ascending = False)\n",
        "df_item_count.columns = ['CountItemId']\n",
        "df_item_count_5 = df_item_count[df_item_count['CountItemId'] < 5]\n",
        "# Lọc khỏi dataset những ItemId có ít hơn 5 lượt xuất hiện\n",
        "dataset = dataset[~dataset['ItemId'].isin(list(df_item_count_5.index))]"
      ],
      "metadata": {
        "id": "HjL3JDmqueu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1.2. Phân chia dữ liệu train/test\n",
        "Từ tập dữ liệu train ta sẽ tách ra 7 ngày cuối cùng làm dữ liệu test. Đối với dữ liệu còn lại để việc huấn luyện được nhanh hơn thì chúng ta sẽ chỉ dữ lại 1/4 số lượng các session cho huấn luyện.\n",
        "\n",
        "Khi đó dữ liệu test sẽ có cấu trúc tương tự như train, mỗi session bao gồm các itemIds được sắp xếp theo thứ tự thời gian. Từ list các itemId liền trước ta cần dự báo itemId tiếp theo có khả năng được click. Các dữ liệu trên test được xem như là session mới hoàn toàn và được sử dụng để kiểm tra mức độ dự báo chuẩn xác của mô hình được huấn luyện từ tập dữ liệu train.\n",
        "\n",
        "Bên dưới ta sẽ thực hành phân chia train/test cho mô hình."
      ],
      "metadata": {
        "id": "qcQ1zlLSwI6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta\n",
        "# Phân chia tập train/test sao cho tập test là 7 ngày gần đây nhất và train là dữ liệu còn lại\n",
        "maxdate = dataset['DateTime'].max()\n",
        "mindate7 = maxdate - timedelta(days = 7)\n",
        "test = dataset[dataset['DateTime'] >= mindate7]\n",
        "dataset = dataset[dataset['DateTime'] <= mindate7]"
      ],
      "metadata": {
        "id": "ubvdZv0kuiTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lấy ra ngẫu nhiên 1/4 số lượng các session cho huấn luyện."
      ],
      "metadata": {
        "id": "fT87eD-DwFt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# list các sessionIds\n",
        "sessIds = list(dataset['SessionId'].unique())\n",
        "# Lấy ngẫu nhiên 1/4 số lượng các session\n",
        "n_filter = int(len(sessIds)/4)\n",
        "np.random.shuffle(sessIds)\n",
        "sessIdsFilter = sessIds[:n_filter]\n",
        "# Lựa chọn các 1/4 session làm dataset train (dữ liệu này bao gồm cả train và validation)\n",
        "# Set index là sessionId để filter nhanh hơn\n",
        "dataset.set_index('SessionId', inplace=True)\n",
        "dataset_filter = dataset[dataset.index.isin(sessIdsFilter)]\n",
        "dataset_filter = dataset_filter.reset_index()"
      ],
      "metadata": {
        "id": "SUjdMcXCul4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Khởi tạo chuỗi các itemId sắp xếp theo thời gian trên mỗi session. Mỗi một itemId sẽ tương ứng với giá trị thời gian của nó. Cấu trúc của các train_sess, test_sess có dạng:\n",
        "\n",
        "['sessionId': {'itemId1':'Timestamp1', ..., 'itemId_n':'Timestamp_n'}]"
      ],
      "metadata": {
        "id": "KvJdmZLfwDG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lấy ra dictionary có dạng {SessionId:{ItemId1:Timestamp1, ItemId2:Timestamp2, ...}}\n",
        "train_sess = dataset_filter[['SessionId', 'ItemId', 'Timestamp']].groupby('SessionId').apply(lambda x: dict(zip(x['ItemId'], x['Timestamp'])))\n",
        "test_sess = test[['SessionId', 'ItemId', 'Timestamp']].groupby('SessionId').apply(lambda x: dict(zip(x['ItemId'], x['Timestamp'])))"
      ],
      "metadata": {
        "id": "uhskGyAbutRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_sess[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1fIFY_o1d9q",
        "outputId": "a56de044-e18d-4f5d-f9d8-703018c5d35e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SessionId\n",
            "1     {214536502: '1396867869.277000', 214536500: '1...\n",
            "6     {214701242: '1396803500.848000', 214826623: '1...\n",
            "16                     {214684093: '1396704053.092000'}\n",
            "22    {214837485: '1396747860.419000', 214837487: '1...\n",
            "23                     {214718203: '1396598208.356000'}\n",
            "26    {214579288: '1396802575.741000', 214714790: '1...\n",
            "27    {214827028: '1396856412.650000', 214827017: '1...\n",
            "29    {214532036: '1396460527.324000', 214700432: '1...\n",
            "37    {214826769: '1396628767.882000', 214537967: '1...\n",
            "44    {214820441: '1396849890.888000', 214826897: '1...\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_sess[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbxiY7262QML",
        "outputId": "995ff191-8863-4d20-fb06-99469064aacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SessionId\n",
            "11255548    {214830939: '1411588414.517000', 214854444: '1...\n",
            "11255549    {214716973: '1411640755.459000', 214716937: '1...\n",
            "11255551                     {214545500: '1411838500.441000'}\n",
            "11255552    {214853100: '1411657491.567000', 214537239: '1...\n",
            "11255553    {214540020: '1411846389.986000', 214819723: '1...\n",
            "11255554    {214850752: '1411600883.048000', 214686879: '1...\n",
            "11255556    {214563189: '1411821070.438000', 214712051: '1...\n",
            "11255557    {214834922: '1411724558.366000', 214856831: '1...\n",
            "11255558                     {214854767: '1411671743.296000'}\n",
            "11255559                     {214512605: '1411997055.971000'}\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1.3. Preprocessing data\n",
        "Ở bước này ta sẽ khởi tạo input và output cho mô hình.\n",
        "\n",
        "Input của mô hình là list các itemIds trong quá khứ và Output là itemId ở vị trí hiện tại. Qúa trình khởi tạo các Input và Output trên một session được thực hiện tịnh tiến từ vị trí itemID đầu tiên cho đến cuối cùng.\n",
        "\n",
        "Ví dụ: Chúng ta có sessionId = [itemId_1, itemId_2, ..., itemId_n] Như vậy sau các cặp (input, output) sẽ là:\n",
        "\n",
        "cặp thứ 1: ([itemId_1], [itemId_2])\n",
        "cặp thứ 2: ([itemId_1, itemId_2], [itemId_3])\n",
        "\n",
        "…\n",
        "\n",
        "cặp thứ n-1: ([itemId_1, itemId_2,..., itemId_(n-1)], [itemId_n])"
      ],
      "metadata": {
        "id": "sUV-YdXzv_vU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sessDict = {214834865: '1396808691.295000', 214706441: '1396808691.426000', 214820225: '1396808691.422000'}\n",
        "\n",
        "def _preprocess_sess_dict(sessDict):\n",
        "    sessDictTime = dict([(v, k) for (k, v) in sessDict.items()])\n",
        "    sessSort = sorted(sessDictTime.items(), reverse = False)\n",
        "    times = [item[0] for item in sessSort]\n",
        "    itemIds = [item[1] for item in sessSort]\n",
        "    inp_seq = []\n",
        "    labels = []\n",
        "    inp_time = []\n",
        "\n",
        "    for i in range(len(sessSort)):\n",
        "        if i >= 1:\n",
        "            inp_seq += [itemIds[:i]]\n",
        "            labels += [itemIds[i]]\n",
        "            inp_time += [times[i]]\n",
        "    return inp_seq, inp_time, labels, itemIds\n",
        "\n",
        "inp_seq, inp_time, labels, itemIds = _preprocess_sess_dict(sessDict)\n",
        "print('input sequences: ', inp_seq)\n",
        "print('input times: ', inp_time)\n",
        "print('targets: ', labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQA0sy0Zuxy3",
        "outputId": "386d1552-1247-4c06-e9ad-f6a754043935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input sequences:  [[214834865], [214834865, 214820225]]\n",
            "input times:  ['1396808691.422000', '1396808691.426000']\n",
            "targets:  [214820225, 214706441]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo chuỗi input và output cho toàn bộ các session\n",
        "def _preprocess_data(data_sess):\n",
        "    inp_seqs = []\n",
        "    inp_times = []\n",
        "    labels = []\n",
        "    sequences = []\n",
        "    sessIds = list(data_sess.index)\n",
        "    for sessId in sessIds:\n",
        "        sessDict = data_sess.loc[sessId]\n",
        "        inp_seq, inp_time, label, sequence = _preprocess_sess_dict(sessDict)\n",
        "        inp_seqs += inp_seq\n",
        "        inp_times += inp_time\n",
        "        labels += label\n",
        "        sequences += sequence\n",
        "    return inp_seqs, inp_times, labels, sequences\n",
        "\n",
        "train_inp_seqs, train_inp_dates, train_labs, train_sequences = _preprocess_data(train_sess)\n",
        "test_inp_seqs, test_inp_dates, test_labs, test_sequences = _preprocess_data(test_sess)\n",
        "\n",
        "train = (train_inp_seqs, train_labs)\n",
        "test = (test_inp_seqs, test_labs)\n",
        "\n",
        "print('Done.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGtJF8wtu0Yy",
        "outputId": "9647b1a2-89ba-4602-e2b3-617fbf15cc6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu_wAgVQ4KEd",
        "outputId": "23167aec-d515-4590-80b0-a85f145d8157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do kích thước dữ liệu là khá lớn nên để thuận lợi cho những lượt train sau ta nên lưu dữ liệu của train và test vào một folder là yoochoose-data-1-4.\n",
        "import pickle\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "pwd = pathlib.Path() \n",
        "saved_data_path = pwd / \"yoochoose-data\"\n",
        "\n",
        "def _save_file(filename, obj):\n",
        "    print(filename)\n",
        "    with open(filename, 'wb') as fn:\n",
        "        pickle.dump(obj, fn)\n",
        "\n",
        "# Tạo folder yoochoose-data-4 để lưu dữ liệu train/test nếu chưa tồn tại\n",
        "if not os.path.exists(saved_data_path):\n",
        "    os.mkdir(saved_data_path)\n",
        "\n",
        "# Lưu train/test\n",
        "_save_file(saved_data_path / \"train.pkl\", train)\n",
        "_save_file(saved_data_path / \"test.pkl\", test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGAmUOUhu4Yf",
        "outputId": "40c285e1-1a76-41f3-bcba-4be75e06905a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yoochoose-data/train.pkl\n",
            "yoochoose-data/test.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ở những lượt huấn luyện sau ta chỉ cần load lại những dữ liệu train/test đã lưu tại folder yoochoose-data-4\n",
        "import pickle\n",
        "\n",
        "def _load_file(filename):\n",
        "  with open(filename, 'rb') as fn:\n",
        "    data = pickle.load(fn)\n",
        "  return data\n",
        "\n",
        "# Load dữ liệu train/test từ folder\n",
        "train = _load_file(saved_data_path / \"train.pkl\")\n",
        "test = _load_file(saved_data_path / \"test.pkl\") \n"
      ],
      "metadata": {
        "id": "CgetwYNAu8Cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1.4. Khởi tạo dictionary\n",
        "Chúng ta cần sử dụng dictionary để nhúng itemId của mỗi một sản phẩm thành một index sao cho mỗi chỉ số này là duy nhất đối với mỗi itemId. Từ index ta có thể tạo ra được các véc tơ one-hot dễ dàng làm đầu vào cho huấn luyện mô hình ở bước embedding."
      ],
      "metadata": {
        "id": "2v-v_QkSvw-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Các token default\n",
        "PAD_token = 0  # token padding cho câu ngắn\n",
        "\n",
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.trimmed = False\n",
        "        self.item2index = {}\n",
        "        self.item2count = {}\n",
        "        self.index2item = {PAD_token: \"PAD\"}\n",
        "        self.num_items = 1  # số lượng mặc định ban đầu là 1 ứng với PAD_token\n",
        "\n",
        "    def addSenquence(self, data):\n",
        "        for sequence in data:\n",
        "          for item in sequence:\n",
        "              self.addItem(item)\n",
        "\n",
        "    # Thêm một item vào hệ thống\n",
        "    def addItem(self, item):\n",
        "        if item not in self.item2index:\n",
        "            self.item2index[item] = self.num_items\n",
        "            self.item2count[item] = 1\n",
        "            self.index2item[self.num_items] = item\n",
        "            self.num_items += 1\n",
        "        else:\n",
        "            self.item2count[item] += 1\n",
        "\n",
        "    # Loại các item dưới ngưỡng xuất hiện min_count\n",
        "    def trim(self, min_count):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "        \n",
        "        keep_items = []\n",
        "\n",
        "        for k, v in self.item2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_items.append(k)\n",
        "\n",
        "        print('keep_items {} / {} = {:.4f}'.format(\n",
        "            len(keep_items), len(self.item2index), len(keep_items) / len(self.item2index)\n",
        "        ))\n",
        "\n",
        "        # Khởi tạo lại từ điển\n",
        "        self.item2index = {}\n",
        "        self.item2count = {}\n",
        "        self.index2item = {PAD_token: \"PAD\"}\n",
        "        self.num_items = 1\n",
        "\n",
        "        # Thêm các items vào từ điển\n",
        "        for item in keep_items:\n",
        "            self.addItem(item)\n",
        "\n",
        "    # Hàm convert sequence về chuỗi các indices\n",
        "    def _seqItem2seqIndex(self, x):\n",
        "        return [voc.item2index[item] if item in voc.item2index else 0 for item in x]\n"
      ],
      "metadata": {
        "id": "HPWsaVUAvCFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lấy toàn bộ list các itemIds trong các session.\n",
        "from itertools import chain\n",
        "seq_targets = [train[1]] + [test[1]]\n",
        "sessionIds = list(chain.from_iterable(seq_targets))\n",
        "sessionIds = set(sessionIds)\n",
        "print('Number of sessionIds: ', len(sessionIds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg8dy1VrvFrp",
        "outputId": "0a66a809-9851-4c54-ad6c-43b3a694d32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessionIds:  33750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo vocabullary cho bộ dữ liệu.\n",
        "voc = Voc('DictItemId')\n",
        "voc.addSenquence(seq_targets)\n",
        "\n",
        "# Convert thử nghiệm một sequence itemIds\n",
        "print('sequence of itemIds: ', train[0][7])\n",
        "print('converted indices: ', voc._seqItem2seqIndex(train[0][7]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HeovlE_vHwy",
        "outputId": "1473fa66-9b85-4052-aa0f-0ab9076dcd98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sequence of itemIds:  [214821275, 214821371, 214717089, 214563337, 214706462, 214717436]\n",
            "converted indices:  [913, 3, 4, 5, 6, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tiếp theo ta sẽ chuyển dữ liệu train, test từ item sang indices của item\n",
        "train_x_index = [voc._seqItem2seqIndex(seq) for seq in train[0]]\n",
        "test_x_index = [voc._seqItem2seqIndex(seq) for seq in test[0]]\n",
        "train_y_index = voc._seqItem2seqIndex(train[1])\n",
        "test_y_index = voc._seqItem2seqIndex(test[1])\n",
        "train_index = (train_x_index, train_y_index)\n",
        "test_index = (test_x_index, test_y_index)"
      ],
      "metadata": {
        "id": "A7QQbBZ3vJuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Từ 2 tập dữ liệu train_index và test_index ban đầu ta sẽ phân chia thành 3 tập train/test và validation như sau:\n",
        "\n",
        "Mỗi tập dữ liệu bao gồm 2 phần: input bao gồm chuỗi các itemId liên tiếp, output là itemId tiếp theo trong được khách hàng click.\n",
        "\n",
        "Dữ liệu validation được rút ra từ dữ liệu train set theo tỷ lệ được qui định tại valid_portion. Phần còn lại của train set được dữ làm tập train set mới.\n",
        "\n",
        "Dữ liệu test được tính toàn trực tiếp từ tập test set.\n",
        "\n",
        "Đối với dữ liệu input, chuỗi dữ liệu sẽ được truncate về độ dài maxlen nếu nó vượt qua maxlen."
      ],
      "metadata": {
        "id": "W-SAi1fZvcH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(root='', valid_portion=0.1, maxlen=19, sort_by_len=False, train_set=None, test_set=None):\n",
        "    \"\"\"Load dataset từ root\n",
        "    root: folder dữ liệu train, trong trường hợp train_set, test_set tồn tại thì không sử dụng train_set và test_set\n",
        "    valid_portion: tỷ lệ phân chia dữ liệu validation/train\n",
        "    maxlen: độ dài lớn nhất của sequence\n",
        "    sort_by_len: có sort theo chiều dài các session trước khi chia hay không?\n",
        "    train_set: training dataset\n",
        "    test_set:  test dataset\n",
        "    \"\"\"\n",
        "    \n",
        "    # Load the dataset\n",
        "    if train_set is None and test_set is None:\n",
        "        path_train_data = os.path.join(root, 'train.pkl')\n",
        "        path_test_data = os.path.join(root, 'test.pkl')\n",
        "        with open(path_train_data, 'rb') as f1:\n",
        "            train_set = pickle.load(f1)\n",
        "\n",
        "        with open(path_test_data, 'rb') as f2:\n",
        "            test_set = pickle.load(f2)\n",
        "\n",
        "    if maxlen:\n",
        "        new_train_set_x = []\n",
        "        new_train_set_y = []\n",
        "        # Lọc dữ liệu sequence đến maxlen\n",
        "        for x, y in zip(train_set[0], train_set[1]):\n",
        "            if len(x) < maxlen:\n",
        "                new_train_set_x.append(x)\n",
        "                new_train_set_y.append(y)\n",
        "            else:\n",
        "                new_train_set_x.append(x[:maxlen])\n",
        "                new_train_set_y.append(y)\n",
        "        train_set = (new_train_set_x, new_train_set_y)\n",
        "        del new_train_set_x, new_train_set_y\n",
        "\n",
        "        new_test_set_x = []\n",
        "        new_test_set_y = []\n",
        "        for xx, yy in zip(test_set[0], test_set[1]):\n",
        "            if len(xx) < maxlen:\n",
        "                new_test_set_x.append(xx)\n",
        "                new_test_set_y.append(yy)\n",
        "            else:\n",
        "                new_test_set_x.append(xx[:maxlen])\n",
        "                new_test_set_y.append(yy)\n",
        "        test_set = (new_test_set_x, new_test_set_y)\n",
        "        del new_test_set_x, new_test_set_y\n",
        "\n",
        "    # phân chia tập train thành train và validation\n",
        "    train_set_x, train_set_y = train_set\n",
        "    n_samples = len(train_set_x)\n",
        "    sidx = np.arange(n_samples, dtype='int32')\n",
        "    np.random.shuffle(sidx)\n",
        "    n_train = int(np.round(n_samples * (1. - valid_portion)))\n",
        "    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]\n",
        "    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]\n",
        "    train_set_x = [train_set_x[s] for s in sidx[:n_train]]\n",
        "    train_set_y = [train_set_y[s] for s in sidx[:n_train]]\n",
        "\n",
        "    (test_set_x, test_set_y) = test_set\n",
        "\n",
        "    # Trả về indices thứ tự độ dài của mỗi phần tử trong seq\n",
        "    def len_argsort(seq):\n",
        "        return sorted(range(len(seq)), key=lambda x: len(seq[x]))\n",
        "\n",
        "    # Sắp xếp session theo độ dài tăng dần\n",
        "    if sort_by_len:\n",
        "        sorted_index = len_argsort(test_set_x)\n",
        "        test_set_x = [test_set_x[i] for i in sorted_index]\n",
        "        test_set_y = [test_set_y[i] for i in sorted_index]\n",
        "\n",
        "        sorted_index = len_argsort(valid_set_x)\n",
        "        valid_set_x = [valid_set_x[i] for i in sorted_index]\n",
        "        valid_set_y = [valid_set_y[i] for i in sorted_index]\n",
        "\n",
        "    train = (train_set_x, train_set_y)\n",
        "    valid = (valid_set_x, valid_set_y)\n",
        "    test = (test_set_x, test_set_y)\n",
        "    return train, valid, test"
      ],
      "metadata": {
        "id": "ylT9tyJNvM1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2. Data Loader\n",
        "Để streaming dữ liệu theo batch thì ta cần sử dụng class DataLoader của pytorch. Class này có chức năng tương tự như ImageDataGenerator trong tensorflow và keras. Nó sẽ cho phép ta sử dụng generator để sinh dữ liệu cho từng batch huấn luyện. Do đó ta sẽ có thể huấn luyện được những mô hình từ dữ liệu có kích thước lớn hơn RAM gấp rất nhiều lần. Data Loader trong pytorch sẽ sử dụng dữ liệu là các class Dataset của pytorch như bên dưới.\n",
        "\n",
        "4.2.1. RecSysDataset\n",
        "Dataset sẽ có dữ liệu hoàn toàn giống với tập train/test và validation mà ta đã phân chia ở bước trên. Chúng được tạo ra đơn thuần là để thích hợp với định dạng data được sử dụng trong quá trình khởi tạo DataLoader."
      ],
      "metadata": {
        "id": "L-tN6hxIva7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class RecSysDataset(Dataset):\n",
        "    \"\"\"define the pytorch Dataset class for yoochoose and diginetica datasets.\n",
        "    \"\"\"\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        print('-'*50)\n",
        "        print('Dataset info:')\n",
        "        print('Number of sessions: {}'.format(len(data[0])))\n",
        "        print('-'*50)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        session_items = self.data[0][index]\n",
        "        target_item = self.data[1][index]\n",
        "        return session_items, target_item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[0])"
      ],
      "metadata": {
        "id": "z5ODyfAHvPVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2.2. Hàm phụ trợ\n",
        "Ngoài ra để tùy biến các dữ liệu từ Dataset, ta có thể truyền vào DataLoader thông qua tham số collate_fn một hàm số có tác dụng biến đổi dữ liệu.\n",
        "\n",
        "Đối với mô hình này ta cũng sẽ sử dụng hàm collate_fn() như bên dưới để biến đổi data (chính là các batch) theo các bước như sau:\n",
        "\n",
        "Sắp xếp độ dài input sequence theo độ dài list từ cao xuống thấp. Việc này sẽ giúp cho quá trình huấn luyện nhanh hơn.\n",
        "\n",
        "Padding thêm 0 vào dữ liệu để độ dài list bằng nhau và bằng với độ dài của input sequence lớn nhất trong batch.\n",
        "\n",
        "transpose dữ liệu từ batch_size x maxlen --> maxlen x batch_size\n",
        "\n",
        "Cuối cùng trả về kết quả ngoài list các chuỗi sessions, list các labels còn trả thêm list các lens ghi nhận độ dài của các sesssions."
      ],
      "metadata": {
        "id": "7vXm2IYsvXPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def collate_fn(data):\n",
        "    \"\"\"\n",
        "    Hàm số này sẽ được sử dụng để pad session về max length\n",
        "    Args: \n",
        "      data: batch truyền vào\n",
        "    return: \n",
        "      batch data đã được pad length có shape maxlen x batch_size\n",
        "    \"\"\"\n",
        "    # Sort batch theo độ dài của input_sequence từ cao xuống thấp\n",
        "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "    lens = [len(sess) for sess, label in data]\n",
        "    labels = []\n",
        "    # Padding batch size\n",
        "    padded_sesss = torch.zeros(len(data), max(lens)).long()\n",
        "    for i, (sess, label) in enumerate(data):\n",
        "        padded_sesss[i,:lens[i]] = torch.LongTensor(sess)\n",
        "        labels.append(label)\n",
        "    \n",
        "    # Transpose dữ liệu từ batch_size x maxlen --> maxlen x batch_size\n",
        "    padded_sesss = padded_sesss.transpose(0,1)\n",
        "    return padded_sesss, torch.tensor(labels).long(), lens"
      ],
      "metadata": {
        "id": "_pxujiZ4vRpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3. Metric\n",
        "Có 2 metrics chính để đo lường hiệu quả của mô hình recommendation đó là:\n",
        "\n",
        "Recall@k : Metric của dữ liệu bao gồm tỷ lệ xuất hiện ground truth của itemId trong top \n",
        " sản phẩm được suggest có xác suất lớn nhất. Tỷ lệ này cho biết khả năng khách hàng sẽ click vào một sản phẩm được suggest từ mô hình với xác suất là bao nhiêu. Do đó giá trị của nó càng lớn thì mô hình sẽ có độ chuẩn xác càng cao. Nếu recall@20 = 10% có nghĩa là nếu áp dụng mô hình để suggest ra 20 sản phẩm cho khách hàng thì khả năng họ có click vào sản phẩm là 10%.\n",
        "\n",
        "mrr@k: Chúng ta sẽ quan tâm trong trường hợp ground truth của itemId nằm trong top \n",
        " sản phẩm được suggest thì thứ tự là bao nhiêu? Nếu vị trí của nó càng nhỏ thì độ chính xác của mô hình càng cao. mrr@k sẽ là nghịch đảo vị trí của ground truth trong trường hợp nó nằm trong top \n",
        " sản phẩm được suggest. Do đó mrr@k càng lớn thì mô hình càng chất lượng.\n",
        "\n",
        "Để tính toán các metrics trên sẽ dựa trên ground truth và top \n",
        " sản phẩm được suggest từ mô hình như bên dưới:"
      ],
      "metadata": {
        "id": "E6k0nVe3wklD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def get_recall(indices, targets):\n",
        "    \"\"\"\n",
        "    Tính toán chỉ số recall cho một tập hợp predictions và targets\n",
        "    Args:\n",
        "        indices (Bxk): torch.LongTensor. top-k indices được dự báo từ mô hình model.\n",
        "        targets (B): torch.LongTensor. actual target indices.\n",
        "    Returns:\n",
        "        recall (float): the recall score\n",
        "    \"\"\"\n",
        "    # copy targets k lần để trở thành kích thước Bxk\n",
        "    targets = targets.view(-1, 1).expand_as(indices)\n",
        "    # so sánh targets với indices để tìm ra vị trí mà khách hàng sẽ hit.\n",
        "    hits = (targets == indices).to(device)\n",
        "    hits = hits.double()\n",
        "    if targets.size(0) == 0:\n",
        "        return 0\n",
        "    # Đếm số hit\n",
        "    n_hits = torch.sum(hits)\n",
        "    recall = n_hits / targets.size(0)\n",
        "    return recall\n",
        "\n",
        "\n",
        "def get_mrr(indices, targets):\n",
        "    \"\"\"\n",
        "    Tính toán chỉ số MRR cho một tập hợp predictions và targets\n",
        "    Args:\n",
        "        indices (Bxk): torch.LongTensor. top-k indices được dự báo từ mô hình model.\n",
        "        targets (B): torch.LongTensor. actual target indices.\n",
        "    Returns:\n",
        "        recall (float): the MRR score\n",
        "    \"\"\"\n",
        "    tmp = targets.view(-1, 1)\n",
        "    targets = tmp.expand_as(indices)\n",
        "    hits = (targets == indices).to(device)\n",
        "    hits = hits.double()\n",
        "    if hits.sum() == 0:\n",
        "      return 0\n",
        "    argsort = []\n",
        "    for i in np.arange(hits.shape[0]):\n",
        "      index_col = torch.where(hits[i, :] == 1)[0]+1\n",
        "      if index_col.shape[0] != 0:\n",
        "        argsort.append(index_col.double())\n",
        "    inv_argsort = [1/item for item in argsort]\n",
        "    mrr = sum(inv_argsort)/hits.shape[0]\n",
        "    return mrr\n",
        "\n",
        "\n",
        "def evaluate(logits, targets, k=20):\n",
        "    \"\"\"\n",
        "    Đánh giá model sử dụng Recall@K, MRR@K scores.\n",
        "    Args:\n",
        "        logits (B,C): torch.LongTensor. giá trị predicted logit cho itemId tiếp theo.\n",
        "        targets (B): torch.LongTensor. actual target indices.\n",
        "    Returns:\n",
        "        recall (float): the recall score\n",
        "        mrr (float): the mrr score\n",
        "    \"\"\"\n",
        "    # Tìm ra indices của topk lớn nhất các giá trị dự báo.\n",
        "    _, indices = torch.topk(logits, k, -1)\n",
        "    recall = get_recall(indices, targets)\n",
        "    mrr = get_mrr(indices, targets)\n",
        "    return recall, mrr"
      ],
      "metadata": {
        "id": "EOCcaEv9wlTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hàm evaluate() sẽ tính toán đồng thời cả 2 chỉ số là recall@k và mrr@k. Tham số của hàm evaluate() bao gồm:\n",
        "\n",
        "logits: Kích thước BxC trong đó B là batch_size và C là số class. Mỗi dòng của logits là phân phối xác suất dự báo cho itemId tiếp theo.\n",
        "\n",
        "targets: Kích thước B trong đó B là batch_size. Đây là index của itemId mà khách hàng đã click và chính là ground truth của mô hình.\n",
        "\n",
        "Kiểm tra hàm evaluate()."
      ],
      "metadata": {
        "id": "koLtBLkjwogJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "logits = torch.tensor([[0.1, 0.2, 0.7],\n",
        "                       [0.4, 0.1, 0.5],\n",
        "                       [0.1, 0.2, 0.7]]).to(device)\n",
        "\n",
        "targets = torch.tensor([1, 2, 2]).to(device)\n",
        "\n",
        "evaluate(logits = logits, targets = targets, k = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDXhoPYVwowj",
        "outputId": "c68b064f-abc6-43a1-fc5d-f54a4e1bf9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1., device='cuda:0', dtype=torch.float64),\n",
              " tensor([0.8333], device='cuda:0', dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.4. Model NARM\n",
        "4.4.1. Các layer của NARM\n",
        "Embedding Layer: Là layer nhúng giúp mã hóa các item index thành những véc tơ với chiều xác định bằng embedding_dim. Embedding Layer sẽ nhận đầu vào là một sequence của các item index. Layer này sẽ thực hiện 2 biến đổi chính:\n",
        "\n",
        "Đầu tiên mỗi một item index sẽ được mã hóa về véc tơ one-hot (là véc tơ đơn vị có giá trị tại vị trí index = 1 và các vị trí khác bằng 0). Như vậy kích thước của véc tơ one-hot sẽ bằng kích thước của từ điển. Lấy ví dụ: Nếu từ điển có 10000 từ với index nhận giá trị từ 1-10000, khi đó một từ có index = 2 sẽ được mã hóa thành véc tơ [0, 1, 0, …, 0]. Tức vị trí số 2 của véc tơ bằng 1 và các vị trí còn lại bằng 0.\n",
        "\n",
        "Sau khi mã hóa xong toàn bộ các từ trong câu thì input của chuỗi item index sẽ trở thành ma trận có kích thước là max_len x vocabulary_size. Khi đó để giảm chiều của dữ liệu ta sẽ sử dụng một phép chiếu linear projection để giảm chiều từ vocabulary_size về embedding_dim. Như vậy sau cùng thu được ma trận kích thước max_len x embedding_dim. Lưu ý: ta giả định là không quan tâm đến batch_size nên kích thước ma trận ở trên chưa bao gồm batch_size.\n",
        "\n",
        "Dropout: Layer này có tác dụng tắt đi ngẫu nhiên một số lượng kết nối liên kết giữa 2 layers để giảm thiểu overfitting cho mô hình.\n",
        "\n",
        "GRU: Layer GRU là trọng tâm của mô hình, thực hiện quá trình dự báo chuỗi. Mô hình bao gồm nhiều time step và mỗi một time step sẽ trả ra phân phối xác suất đại diện cho từ ở vị trí đó. Kết quả trả ra của layer GRU goòm 2 thành phần: (output, hidden).\n",
        "\n",
        "Trong đó output sẽ chứa toàn bộ các hidden véc tơ tại toàn bộ các time step \n",
        " tại layer GRU cuối cùng (chúng ta có thể chồng nhiều layers GRU nối tiếp nhau thông qua khai báo ở tham số num_layers và chúng đều đưa ra cùng một kết quả cuối cùng mà không phụ thuộc vào num_layers, kết quả trả ra sẽ được tính từ layer cuối). output sẽ có kích thước là max_len x batch_size x (n_directions*hidden_size). Sở dĩ có thêm n_direction là vì mô hình được thực hiện theo một chiều từ trái qua phải hoặc 2 chiều từ trái qua phải và từ phải qua trái. Trường hợp 2 chiều thì tại mỗi time step sẽ có 2 hidden véc tơ đại diện cho 2 chiều.\n",
        "\n",
        "Tham số thứ 2 trả ra từ layer GRU là hidden chính là list các véc tơ hidden tại time step cuối cùng của toàn bộ các layer GRU. Như vậy hidden sẽ có kích thước là (num_layers*n_directions) x batch_size x hidden_size. Để thu được hidden state của layer GRU cuối cùng thì ta sẽ trích suất véc tơ cuối cùng (chính là công thức ht = hidden[-1] bên dưới).\n",
        "\n",
        "Quá trình tính attention"
      ],
      "metadata": {
        "id": "lqxZvFaEwsoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class NARM(nn.Module):\n",
        "    def __init__(self, hidden_size, n_items, embedding_dim, n_layers=1, dropout=0.25):\n",
        "        super(NARM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_items = n_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(self.n_items, self.embedding_dim, padding_idx = 0)\n",
        "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
        "        # set bidirectional = True for bidirectional\n",
        "        # https://pytorch.org/docs/stable/nn.html?highlight=gru#torch.nn.GRU to get more information\n",
        "        self.gru = nn.GRU(input_size = hidden_size, # number of expected feature of input x \n",
        "                          hidden_size = hidden_size, # number of expected feature of hidden state \n",
        "                          num_layers = n_layers, # number of GRU layers\n",
        "                          dropout=(0 if n_layers == 1 else dropout), # dropout probability apply in encoder network\n",
        "                          bidirectional=True # one or two directions.\n",
        "                         )\n",
        "        self.emb_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_size, self.n_layers)\n",
        "        self.a_1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "        self.a_2 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "        self.v_t = nn.Linear(self.hidden_size, 1, bias=False)\n",
        "        self.ct_dropout = nn.Dropout(0.5)\n",
        "        self.b = nn.Linear(self.embedding_dim, 2 * self.hidden_size, bias=False)\n",
        "        self.sf = nn.Softmax()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        \"\"\"\n",
        "        input_seq: Batch input_sequence. Shape: max_len x batch_size \n",
        "        input_lengths: Batch input lengths. Shape: batch_size\n",
        "        \"\"\"\n",
        "        # Step 1: Convert sequence indexes to embeddings\n",
        "        # shape: (max_length , batch_size , hidden_size)\n",
        "        embedded = self.embedding(input_seq)\n",
        "        # Pack padded batch of sequences for RNN module. Padding zero when length less than max_length of input_lengths.\n",
        "        # shape: (max_length , batch_size , hidden_size)\n",
        "        packed = pack_padded_sequence(embedded, input_lengths)\n",
        "\n",
        "        # Step 2: Forward packed through GRU\n",
        "        # outputs is output of final GRU layer\n",
        "        # hidden is concatenate of all hidden states corresponding with each time step.\n",
        "        # outputs shape: (max_length , batch_size , hidden_size x num_directions)\n",
        "        # hidden shape: (n_layers x num_directions , batch_size , hidden_size)\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        # Unpack padding. Revert of pack_padded_sequence\n",
        "        # outputs shape: (max_length , batch_size , hidden_size x num_directions)\n",
        "        outputs, length = pad_packed_sequence(outputs)\n",
        "\n",
        "        # Step 3: Global Encoder & Local Encoder\n",
        "        # num_directions = 1 -->\n",
        "        # outputs shape:(max_length , batch_size , hidden_size)\n",
        "        # hidden shape: (n_layers , batch_size , hidden_size)\n",
        "        # lấy hidden state tại time step cuối cùng\n",
        "        ht = hidden[-1]\n",
        "        # reshape outputs\n",
        "        outputs = outputs.permute(1, 0, 2) # [batch_size, max_length, hidden_size]     \n",
        "        c_global = ht\n",
        "        # Flatten outputs thành shape: [batch_size, max_length, hidden_size]\n",
        "        gru_output_flatten = outputs.contiguous().view(-1, self.hidden_size)\n",
        "        # Thực hiện một phép chiếu linear projection để tạo các latent variable có shape [batch_size, max_length, hidden_size]\n",
        "        q1 = self.a_1(gru_output_flatten).view(outputs.size()) \n",
        "        # Thực hiện một phép chiếu linear projection để tạo các latent variable có shape [batch_size, max_length, hidden_size]\n",
        "        q2 = self.a_2(ht)\n",
        "        # Ma trận mask đánh dấu vị trí khác 0 trên padding sequence.\n",
        "        mask = torch.where(input_seq.permute(1, 0) > 0, torch.tensor([1.], device = self.device), torch.tensor([0.], device = self.device)) # batch_size x max_len\n",
        "        # Điều chỉnh shape\n",
        "        q2_expand = q2.unsqueeze(1).expand_as(q1) # shape [batch_size, max_len, hidden_size]\n",
        "        q2_masked = mask.unsqueeze(2).expand_as(q1) * q2_expand # batch_size x max_len x hidden_size\n",
        "        # Tính trọng số alpha đo lường similarity giữa các hidden state \n",
        "        alpha = self.v_t(torch.sigmoid(q1 + q2_masked).view(-1, self.hidden_size)).view(mask.size()) # batch_size x max_len\n",
        "        alpha_exp = alpha.unsqueeze(2).expand_as(outputs) # batch_size x max_len x hidden_size\n",
        "        # Tính linear combinition của các hidden state\n",
        "        c_local = torch.sum(alpha_exp * outputs, 1) # (batch_size x hidden_size)\n",
        "\n",
        "        # Véc tơ combinition tổng hợp\n",
        "        c_t = torch.cat([c_local, c_global], 1) # batch_size x (2*hidden_size) \n",
        "        c_t = self.ct_dropout(c_t)\n",
        "        # Tính scores\n",
        "\n",
        "        # Step 4: Decoder\n",
        "        # embedding cho toàn bộ các item\n",
        "        item_indices = torch.arange(self.n_items).to(device) # 1 x n_items\n",
        "        item_embs = self.embedding(item_indices) # n_items x embedding_dim\n",
        "        # reduce dimension by bi-linear projection\n",
        "        B = self.b(item_embs).permute(1, 0) # (2*hidden_size) x n_items\n",
        "        scores = torch.matmul(c_t, B) # batch_size x n_items\n",
        "        # scores = self.sf(scores)\n",
        "        return scores"
      ],
      "metadata": {
        "id": "rJZN_0Fyws7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.4.2. Kiểm tra model NARM"
      ],
      "metadata": {
        "id": "S1nGQszNw3Fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Thử nghiệm model bằng cách giả lập 1 input và thực hiện quá trình feed forward\n",
        "from torch import nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "hidden_size = 3\n",
        "n_layers = 7\n",
        "# embedding = nn.Embedding(11000, hidden_size)\n",
        "input_variable = torch.tensor([[  66,  369,   66, 1272],\n",
        "                                [ 567,  183,   28,  616],\n",
        "                                [ 392, 1558, 1143,  175],\n",
        "                                [ 394,   31,   31, 5558],\n",
        "                                [   0,    0,    0,    0]]).to(device)\n",
        "\n",
        "lengths =  torch.tensor([5, 5, 5, 5]).to('cpu')\n",
        "print('input_seq: \\n', input_variable)\n",
        "print('input_lengths: \\n', lengths)\n",
        "model_test = NARM(hidden_size = hidden_size, n_items  = 100000, embedding_dim = 100, n_layers=1, dropout=0.25).to(device)\n",
        "print('model phrase: \\n', model_test)\n",
        "scores = model_test.forward(input_seq = input_variable, input_lengths = lengths)\n",
        "print('probability distribution: ', scores.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYjF98lqw3fp",
        "outputId": "75aa1030-25c3-451c-be06-309f0455111d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_seq: \n",
            " tensor([[  66,  369,   66, 1272],\n",
            "        [ 567,  183,   28,  616],\n",
            "        [ 392, 1558, 1143,  175],\n",
            "        [ 394,   31,   31, 5558],\n",
            "        [   0,    0,    0,    0]], device='cuda:0')\n",
            "input_lengths: \n",
            " tensor([5, 5, 5, 5])\n",
            "model phrase: \n",
            " NARM(\n",
            "  (embedding): Embedding(100000, 100, padding_idx=0)\n",
            "  (gru): GRU(100, 3)\n",
            "  (emb_dropout): Dropout(p=0.25, inplace=False)\n",
            "  (a_1): Linear(in_features=3, out_features=3, bias=False)\n",
            "  (a_2): Linear(in_features=3, out_features=3, bias=False)\n",
            "  (v_t): Linear(in_features=3, out_features=1, bias=False)\n",
            "  (ct_dropout): Dropout(p=0.5, inplace=False)\n",
            "  (b): Linear(in_features=100, out_features=6, bias=False)\n",
            "  (sf): Softmax(dim=None)\n",
            ")\n",
            "probability distribution:  torch.Size([4, 100000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.5. Validation\n",
        "Hàm validation sẽ sử dụng để tính toán recall@k và mrr@k trên tập dữ liệu validation.\n",
        "\n",
        "Đầu tiên ta sẽ sử dụng model để dự báo xác suất output cho từng batch. valid_loader là một iterator được sử dụng để khởi tạo batch. Sử dụng vòng lặp để để duyệt qua toàn bộ batch của valid_loader và lưu các giá trị recall@k và mrr@k tính được ở mỗi batch vào list. Cuối cùng lấy trung bình của toàn bộ các chỉ số này để thu được recall@k và mrr@k đại diện trên tập validation."
      ],
      "metadata": {
        "id": "B_O8e4ADw8Hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(valid_loader, model):\n",
        "    model.eval()\n",
        "    recalls = []\n",
        "    mrrs = []\n",
        "    with torch.no_grad():\n",
        "        for seq, target, lens in valid_loader:\n",
        "            seq = seq.to(device)\n",
        "            target = target.to(device)\n",
        "            outputs = model(seq, lens)\n",
        "            logits = F.softmax(outputs, dim = 1)\n",
        "            recall, mrr = evaluate(logits, target, k = args['topk'])\n",
        "            recalls.append(recall)\n",
        "            mrrs.append(mrr)\n",
        "    \n",
        "    mean_recall = torch.mean(torch.stack(recalls))\n",
        "    mean_mrr = torch.mean(torch.stack(mrrs))\n",
        "    return mean_recall, mean_mrr"
      ],
      "metadata": {
        "id": "hv7gte2Aw8kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.6. Training model\n",
        "Hàm main() giúp huấn luyện mô hình trên toàn bộ epochs và trả về kết quả là mô hình sau huấn luyện. Bên cạnh đó, mô hình sau huấn luyện sẽ được lưu vào file latest_checkpoint.pth.tar để có thể tái sử dụng về sau.\n",
        "\n",
        "Hàm trainForEpoch() thực hiện huấn luyện mô hình trên mỗi một epoch. Dựa vào Data Loader, chúng ta có thể dễ dàng duyệt qua toàn bộ dataset và training trên từng batch."
      ],
      "metadata": {
        "id": "kLHg0naaw_Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from os.path import join\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.autograd import Variable\n",
        "from torch.backends import cudnn\n",
        "\n",
        "args = {\n",
        "    'dataset_path':'../input/yoochoose/yoochoose-clicks.dat',\n",
        "    'batch_size': 256,\n",
        "    'hidden_size': 100,\n",
        "    'embed_dim': 50,\n",
        "    'epoch': 10,\n",
        "    'lr':0.001,\n",
        "    'lr_dc':0.1,\n",
        "    'lr_dc_step':80,\n",
        "    'test':None,\n",
        "    'topk':20,\n",
        "    'valid_portion':0.1\n",
        "}\n",
        "\n",
        "here = os.path.dirname(os.getcwd())\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def main():\n",
        "    print('Loading data...')\n",
        "    train_data, valid_data, test_data = load_data(train_set=train_index, test_set=test_index)\n",
        "    train_data = RecSysDataset(train_data)\n",
        "    valid_data = RecSysDataset(valid_data)\n",
        "    test_data = RecSysDataset(test_data)\n",
        "    train_loader = DataLoader(train_data, batch_size = args['batch_size'], shuffle = True, collate_fn = collate_fn)\n",
        "    valid_loader = DataLoader(valid_data, batch_size = args['batch_size'], shuffle = False, collate_fn = collate_fn)\n",
        "    test_loader = DataLoader(test_data, batch_size = args['batch_size'], shuffle = False, collate_fn = collate_fn)\n",
        "    print('Complete load data!')\n",
        "    n_items = voc.num_items\n",
        "    model = NARM(hidden_size = args['hidden_size'], n_items = n_items, embedding_dim = args['embed_dim'], n_layers=2, dropout=0.25).to(device)\n",
        "    print('complete load model!')\n",
        "\n",
        "    if args['test'] == 'store_true':\n",
        "        ckpt = torch.load('latest_checkpoint.pth.tar')\n",
        "        model.load_state_dict(ckpt['state_dict'])\n",
        "        recall, mrr = validate(test_loader, model)\n",
        "        print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args['topk'], recall, args['topk'], mrr))\n",
        "        return model\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), args['lr'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = StepLR(optimizer, step_size = args['lr_dc_step'], gamma = args['lr_dc'])\n",
        "\n",
        "    print('start training!')\n",
        "    for epoch in tqdm(range(args['epoch'])):\n",
        "        # train for one epoch\n",
        "        trainForEpoch(train_loader, model, optimizer, epoch, args['epoch'], criterion, log_aggr = 1000)\n",
        "        scheduler.step(epoch = epoch)\n",
        "        recall, mrr = validate(valid_loader, model)\n",
        "        print('Epoch {} validation: Recall@{}: {:.4f}, MRR@{}: {:.4f} \\n'.format(epoch, args['topk'], recall, args['topk'], mrr))\n",
        "\n",
        "        # store best loss and save a model checkpoint\n",
        "        ckpt_dict = {\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "        # Save model checkpoint into 'latest_checkpoint2.pth.tar'\n",
        "        torch.save(ckpt_dict, 'latest_checkpoint.pth.tar')\n",
        "    return model\n",
        "\n",
        "\n",
        "def trainForEpoch(train_loader, model, optimizer, epoch, num_epochs, criterion, log_aggr=1000):\n",
        "    model.train()\n",
        "\n",
        "    sum_epoch_loss = 0\n",
        "\n",
        "    start = time.time()\n",
        "    for i, (seq, target, lens) in enumerate(train_loader):\n",
        "        seq = seq.to(device)\n",
        "        target = target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(seq, lens)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step() \n",
        "\n",
        "        loss_val = loss.item()\n",
        "        sum_epoch_loss += loss_val\n",
        "\n",
        "        iter_num = epoch * len(train_loader) + i + 1\n",
        "\n",
        "        if i % log_aggr == 0:\n",
        "            print('[TRAIN] epoch %d/%d  observation %d/%d batch loss: %.4f (avg %.4f) (%.2f im/s)'\n",
        "                % (epoch + 1, num_epochs, i, len(train_loader), loss_val, sum_epoch_loss / (i + 1),\n",
        "                  len(seq) / (time.time() - start)))\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "model = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEOWd9Lgw_XB",
        "outputId": "3631e017-eafb-4a62-86bc-55225015e3af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 3806780\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 422976\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 416838\n",
            "--------------------------------------------------\n",
            "Complete load data!\n",
            "complete load model!\n",
            "start training!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] epoch 1/10  observation 0/14871 batch loss: 10.7536 (avg 10.7536) (19.84 im/s)\n",
            "[TRAIN] epoch 1/10  observation 1000/14871 batch loss: 8.8231 (avg 9.4189) (1132.23 im/s)\n",
            "[TRAIN] epoch 1/10  observation 2000/14871 batch loss: 8.4013 (avg 8.9754) (1342.88 im/s)\n",
            "[TRAIN] epoch 1/10  observation 3000/14871 batch loss: 8.2948 (avg 8.7767) (1189.25 im/s)\n",
            "[TRAIN] epoch 1/10  observation 4000/14871 batch loss: 8.0520 (avg 8.6459) (1177.64 im/s)\n",
            "[TRAIN] epoch 1/10  observation 5000/14871 batch loss: 8.0060 (avg 8.5413) (1227.48 im/s)\n",
            "[TRAIN] epoch 1/10  observation 6000/14871 batch loss: 8.0486 (avg 8.4513) (1301.94 im/s)\n",
            "[TRAIN] epoch 1/10  observation 7000/14871 batch loss: 7.8767 (avg 8.3647) (1329.70 im/s)\n",
            "[TRAIN] epoch 1/10  observation 8000/14871 batch loss: 7.4650 (avg 8.2786) (1332.93 im/s)\n",
            "[TRAIN] epoch 1/10  observation 9000/14871 batch loss: 7.5303 (avg 8.1952) (1099.32 im/s)\n",
            "[TRAIN] epoch 1/10  observation 10000/14871 batch loss: 7.4389 (avg 8.1143) (1204.57 im/s)\n",
            "[TRAIN] epoch 1/10  observation 11000/14871 batch loss: 7.1295 (avg 8.0364) (1256.55 im/s)\n",
            "[TRAIN] epoch 1/10  observation 12000/14871 batch loss: 7.4115 (avg 7.9602) (1282.62 im/s)\n",
            "[TRAIN] epoch 1/10  observation 13000/14871 batch loss: 6.9801 (avg 7.8869) (1148.25 im/s)\n",
            "[TRAIN] epoch 1/10  observation 14000/14871 batch loss: 6.9198 (avg 7.8163) (1318.00 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            " 10%|█         | 1/10 [04:44<42:41, 284.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 validation: Recall@20: 0.3509, MRR@20: 0.1266 \n",
            "\n",
            "[TRAIN] epoch 2/10  observation 0/14871 batch loss: 6.6729 (avg 6.6729) (69.26 im/s)\n",
            "[TRAIN] epoch 2/10  observation 1000/14871 batch loss: 6.7268 (avg 6.7336) (1318.24 im/s)\n",
            "[TRAIN] epoch 2/10  observation 2000/14871 batch loss: 6.7519 (avg 6.6957) (1221.14 im/s)\n",
            "[TRAIN] epoch 2/10  observation 3000/14871 batch loss: 6.8528 (avg 6.6656) (1218.58 im/s)\n",
            "[TRAIN] epoch 2/10  observation 4000/14871 batch loss: 6.7631 (avg 6.6363) (1174.15 im/s)\n",
            "[TRAIN] epoch 2/10  observation 5000/14871 batch loss: 6.3496 (avg 6.6060) (1210.22 im/s)\n",
            "[TRAIN] epoch 2/10  observation 6000/14871 batch loss: 6.2374 (avg 6.5812) (1358.86 im/s)\n",
            "[TRAIN] epoch 2/10  observation 7000/14871 batch loss: 6.4348 (avg 6.5560) (1345.12 im/s)\n",
            "[TRAIN] epoch 2/10  observation 8000/14871 batch loss: 6.6238 (avg 6.5324) (1198.37 im/s)\n",
            "[TRAIN] epoch 2/10  observation 9000/14871 batch loss: 6.2324 (avg 6.5095) (1241.48 im/s)\n",
            "[TRAIN] epoch 2/10  observation 10000/14871 batch loss: 6.5767 (avg 6.4881) (1204.22 im/s)\n",
            "[TRAIN] epoch 2/10  observation 11000/14871 batch loss: 6.0393 (avg 6.4687) (1324.66 im/s)\n",
            "[TRAIN] epoch 2/10  observation 12000/14871 batch loss: 6.3235 (avg 6.4501) (1203.29 im/s)\n",
            "[TRAIN] epoch 2/10  observation 13000/14871 batch loss: 6.0004 (avg 6.4313) (1213.48 im/s)\n",
            "[TRAIN] epoch 2/10  observation 14000/14871 batch loss: 6.0623 (avg 6.4138) (1177.44 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [09:32<38:10, 286.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 validation: Recall@20: 0.4422, MRR@20: 0.1618 \n",
            "\n",
            "[TRAIN] epoch 3/10  observation 0/14871 batch loss: 5.7195 (avg 5.7195) (66.26 im/s)\n",
            "[TRAIN] epoch 3/10  observation 1000/14871 batch loss: 6.1800 (avg 6.1222) (1221.18 im/s)\n",
            "[TRAIN] epoch 3/10  observation 2000/14871 batch loss: 6.1897 (avg 6.1097) (1285.25 im/s)\n",
            "[TRAIN] epoch 3/10  observation 3000/14871 batch loss: 5.7414 (avg 6.1044) (1117.51 im/s)\n",
            "[TRAIN] epoch 3/10  observation 4000/14871 batch loss: 5.9538 (avg 6.0960) (1229.62 im/s)\n",
            "[TRAIN] epoch 3/10  observation 5000/14871 batch loss: 5.8709 (avg 6.0869) (1225.71 im/s)\n",
            "[TRAIN] epoch 3/10  observation 6000/14871 batch loss: 5.6937 (avg 6.0781) (1285.66 im/s)\n",
            "[TRAIN] epoch 3/10  observation 7000/14871 batch loss: 5.9374 (avg 6.0701) (1302.75 im/s)\n",
            "[TRAIN] epoch 3/10  observation 8000/14871 batch loss: 5.8108 (avg 6.0623) (1184.36 im/s)\n",
            "[TRAIN] epoch 3/10  observation 9000/14871 batch loss: 5.8695 (avg 6.0540) (1295.76 im/s)\n",
            "[TRAIN] epoch 3/10  observation 10000/14871 batch loss: 5.9524 (avg 6.0457) (1096.43 im/s)\n",
            "[TRAIN] epoch 3/10  observation 11000/14871 batch loss: 6.2676 (avg 6.0374) (1193.54 im/s)\n",
            "[TRAIN] epoch 3/10  observation 12000/14871 batch loss: 5.8662 (avg 6.0309) (1234.61 im/s)\n",
            "[TRAIN] epoch 3/10  observation 13000/14871 batch loss: 5.6897 (avg 6.0240) (1341.95 im/s)\n",
            "[TRAIN] epoch 3/10  observation 14000/14871 batch loss: 6.0362 (avg 6.0176) (1296.92 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [14:17<33:21, 285.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 validation: Recall@20: 0.4806, MRR@20: 0.1799 \n",
            "\n",
            "[TRAIN] epoch 4/10  observation 0/14871 batch loss: 6.1176 (avg 6.1176) (68.06 im/s)\n",
            "[TRAIN] epoch 4/10  observation 1000/14871 batch loss: 5.9332 (avg 5.8812) (1179.13 im/s)\n",
            "[TRAIN] epoch 4/10  observation 2000/14871 batch loss: 5.8021 (avg 5.8840) (1348.79 im/s)\n",
            "[TRAIN] epoch 4/10  observation 3000/14871 batch loss: 6.0745 (avg 5.8795) (1211.25 im/s)\n",
            "[TRAIN] epoch 4/10  observation 4000/14871 batch loss: 5.5612 (avg 5.8775) (1288.51 im/s)\n",
            "[TRAIN] epoch 4/10  observation 5000/14871 batch loss: 5.8868 (avg 5.8738) (1293.30 im/s)\n",
            "[TRAIN] epoch 4/10  observation 6000/14871 batch loss: 5.7497 (avg 5.8688) (1262.56 im/s)\n",
            "[TRAIN] epoch 4/10  observation 7000/14871 batch loss: 5.7795 (avg 5.8655) (1251.15 im/s)\n",
            "[TRAIN] epoch 4/10  observation 8000/14871 batch loss: 5.8746 (avg 5.8619) (1091.86 im/s)\n",
            "[TRAIN] epoch 4/10  observation 9000/14871 batch loss: 5.9962 (avg 5.8611) (1237.72 im/s)\n",
            "[TRAIN] epoch 4/10  observation 10000/14871 batch loss: 5.9164 (avg 5.8583) (1179.73 im/s)\n",
            "[TRAIN] epoch 4/10  observation 11000/14871 batch loss: 5.5239 (avg 5.8558) (1303.35 im/s)\n",
            "[TRAIN] epoch 4/10  observation 12000/14871 batch loss: 5.8325 (avg 5.8517) (1342.34 im/s)\n",
            "[TRAIN] epoch 4/10  observation 13000/14871 batch loss: 5.9671 (avg 5.8494) (1285.64 im/s)\n",
            "[TRAIN] epoch 4/10  observation 14000/14871 batch loss: 5.8635 (avg 5.8461) (1335.32 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [19:00<28:29, 284.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 validation: Recall@20: 0.4990, MRR@20: 0.1894 \n",
            "\n",
            "[TRAIN] epoch 5/10  observation 0/14871 batch loss: 6.1441 (avg 6.1441) (61.04 im/s)\n",
            "[TRAIN] epoch 5/10  observation 1000/14871 batch loss: 6.0914 (avg 5.7686) (1307.86 im/s)\n",
            "[TRAIN] epoch 5/10  observation 2000/14871 batch loss: 5.6276 (avg 5.7668) (1236.84 im/s)\n",
            "[TRAIN] epoch 5/10  observation 3000/14871 batch loss: 5.6784 (avg 5.7659) (1279.20 im/s)\n",
            "[TRAIN] epoch 5/10  observation 4000/14871 batch loss: 6.1927 (avg 5.7630) (1241.63 im/s)\n",
            "[TRAIN] epoch 5/10  observation 5000/14871 batch loss: 5.7466 (avg 5.7625) (1243.90 im/s)\n",
            "[TRAIN] epoch 5/10  observation 6000/14871 batch loss: 5.6098 (avg 5.7605) (1221.24 im/s)\n",
            "[TRAIN] epoch 5/10  observation 7000/14871 batch loss: 6.0929 (avg 5.7587) (1229.87 im/s)\n",
            "[TRAIN] epoch 5/10  observation 8000/14871 batch loss: 5.6931 (avg 5.7580) (1248.01 im/s)\n",
            "[TRAIN] epoch 5/10  observation 9000/14871 batch loss: 5.8061 (avg 5.7579) (1106.74 im/s)\n",
            "[TRAIN] epoch 5/10  observation 10000/14871 batch loss: 5.8642 (avg 5.7565) (1230.53 im/s)\n",
            "[TRAIN] epoch 5/10  observation 11000/14871 batch loss: 5.7369 (avg 5.7553) (1345.76 im/s)\n",
            "[TRAIN] epoch 5/10  observation 12000/14871 batch loss: 5.4066 (avg 5.7542) (1319.20 im/s)\n",
            "[TRAIN] epoch 5/10  observation 13000/14871 batch loss: 5.8530 (avg 5.7528) (1278.73 im/s)\n",
            "[TRAIN] epoch 5/10  observation 14000/14871 batch loss: 5.8249 (avg 5.7523) (1289.93 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [23:47<23:46, 285.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 validation: Recall@20: 0.5076, MRR@20: 0.1942 \n",
            "\n",
            "[TRAIN] epoch 6/10  observation 0/14871 batch loss: 5.4461 (avg 5.4461) (73.87 im/s)\n",
            "[TRAIN] epoch 6/10  observation 1000/14871 batch loss: 5.4517 (avg 5.6861) (944.44 im/s)\n",
            "[TRAIN] epoch 6/10  observation 2000/14871 batch loss: 5.7021 (avg 5.6938) (1117.05 im/s)\n",
            "[TRAIN] epoch 6/10  observation 3000/14871 batch loss: 5.5575 (avg 5.6969) (1250.56 im/s)\n",
            "[TRAIN] epoch 6/10  observation 4000/14871 batch loss: 5.7415 (avg 5.6956) (1104.87 im/s)\n",
            "[TRAIN] epoch 6/10  observation 5000/14871 batch loss: 5.6363 (avg 5.6983) (1202.17 im/s)\n",
            "[TRAIN] epoch 6/10  observation 6000/14871 batch loss: 5.8751 (avg 5.6979) (1356.76 im/s)\n",
            "[TRAIN] epoch 6/10  observation 7000/14871 batch loss: 5.7133 (avg 5.6963) (1064.84 im/s)\n",
            "[TRAIN] epoch 6/10  observation 8000/14871 batch loss: 5.7536 (avg 5.6946) (1213.11 im/s)\n",
            "[TRAIN] epoch 6/10  observation 9000/14871 batch loss: 5.4334 (avg 5.6949) (1287.47 im/s)\n",
            "[TRAIN] epoch 6/10  observation 10000/14871 batch loss: 5.5419 (avg 5.6948) (1251.26 im/s)\n",
            "[TRAIN] epoch 6/10  observation 11000/14871 batch loss: 5.5390 (avg 5.6947) (1346.21 im/s)\n",
            "[TRAIN] epoch 6/10  observation 12000/14871 batch loss: 5.7362 (avg 5.6946) (1271.47 im/s)\n",
            "[TRAIN] epoch 6/10  observation 13000/14871 batch loss: 5.8260 (avg 5.6945) (1331.12 im/s)\n",
            "[TRAIN] epoch 6/10  observation 14000/14871 batch loss: 5.4804 (avg 5.6943) (1188.42 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [28:30<18:58, 284.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 validation: Recall@20: 0.5124, MRR@20: 0.1980 \n",
            "\n",
            "[TRAIN] epoch 7/10  observation 0/14871 batch loss: 5.7761 (avg 5.7761) (75.35 im/s)\n",
            "[TRAIN] epoch 7/10  observation 1000/14871 batch loss: 5.6605 (avg 5.6519) (1286.20 im/s)\n",
            "[TRAIN] epoch 7/10  observation 2000/14871 batch loss: 5.5711 (avg 5.6471) (1249.19 im/s)\n",
            "[TRAIN] epoch 7/10  observation 3000/14871 batch loss: 6.1215 (avg 5.6491) (1326.34 im/s)\n",
            "[TRAIN] epoch 7/10  observation 4000/14871 batch loss: 5.7227 (avg 5.6518) (1366.60 im/s)\n",
            "[TRAIN] epoch 7/10  observation 5000/14871 batch loss: 5.8448 (avg 5.6537) (1318.29 im/s)\n",
            "[TRAIN] epoch 7/10  observation 6000/14871 batch loss: 6.1661 (avg 5.6545) (1143.68 im/s)\n",
            "[TRAIN] epoch 7/10  observation 7000/14871 batch loss: 6.1087 (avg 5.6552) (1326.52 im/s)\n",
            "[TRAIN] epoch 7/10  observation 8000/14871 batch loss: 5.5998 (avg 5.6560) (1248.70 im/s)\n",
            "[TRAIN] epoch 7/10  observation 9000/14871 batch loss: 5.5884 (avg 5.6549) (1183.74 im/s)\n",
            "[TRAIN] epoch 7/10  observation 10000/14871 batch loss: 5.6356 (avg 5.6546) (1244.08 im/s)\n",
            "[TRAIN] epoch 7/10  observation 11000/14871 batch loss: 5.6554 (avg 5.6540) (1235.47 im/s)\n",
            "[TRAIN] epoch 7/10  observation 12000/14871 batch loss: 5.8035 (avg 5.6531) (1200.45 im/s)\n",
            "[TRAIN] epoch 7/10  observation 13000/14871 batch loss: 5.7971 (avg 5.6532) (1288.84 im/s)\n",
            "[TRAIN] epoch 7/10  observation 14000/14871 batch loss: 5.8393 (avg 5.6531) (1312.17 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [33:12<14:11, 283.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 validation: Recall@20: 0.5183, MRR@20: 0.2028 \n",
            "\n",
            "[TRAIN] epoch 8/10  observation 0/14871 batch loss: 5.6259 (avg 5.6259) (74.04 im/s)\n",
            "[TRAIN] epoch 8/10  observation 1000/14871 batch loss: 5.7104 (avg 5.5928) (1322.16 im/s)\n",
            "[TRAIN] epoch 8/10  observation 2000/14871 batch loss: 5.9146 (avg 5.6055) (1225.41 im/s)\n",
            "[TRAIN] epoch 8/10  observation 3000/14871 batch loss: 5.5043 (avg 5.6094) (1343.26 im/s)\n",
            "[TRAIN] epoch 8/10  observation 4000/14871 batch loss: 5.5748 (avg 5.6129) (1335.90 im/s)\n",
            "[TRAIN] epoch 8/10  observation 5000/14871 batch loss: 5.3749 (avg 5.6146) (1209.94 im/s)\n",
            "[TRAIN] epoch 8/10  observation 6000/14871 batch loss: 5.5293 (avg 5.6168) (1235.11 im/s)\n",
            "[TRAIN] epoch 8/10  observation 7000/14871 batch loss: 5.6051 (avg 5.6169) (1256.61 im/s)\n",
            "[TRAIN] epoch 8/10  observation 8000/14871 batch loss: 5.4301 (avg 5.6189) (1258.89 im/s)\n",
            "[TRAIN] epoch 8/10  observation 9000/14871 batch loss: 5.5168 (avg 5.6207) (1301.60 im/s)\n",
            "[TRAIN] epoch 8/10  observation 10000/14871 batch loss: 5.6391 (avg 5.6203) (1331.35 im/s)\n",
            "[TRAIN] epoch 8/10  observation 11000/14871 batch loss: 5.6526 (avg 5.6214) (1183.86 im/s)\n",
            "[TRAIN] epoch 8/10  observation 12000/14871 batch loss: 5.5969 (avg 5.6220) (1315.76 im/s)\n",
            "[TRAIN] epoch 8/10  observation 13000/14871 batch loss: 5.4665 (avg 5.6217) (1212.69 im/s)\n",
            "[TRAIN] epoch 8/10  observation 14000/14871 batch loss: 5.5674 (avg 5.6219) (1074.75 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [37:55<09:27, 283.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 validation: Recall@20: 0.5206, MRR@20: 0.2053 \n",
            "\n",
            "[TRAIN] epoch 9/10  observation 0/14871 batch loss: 5.5715 (avg 5.5715) (58.63 im/s)\n",
            "[TRAIN] epoch 9/10  observation 1000/14871 batch loss: 5.4661 (avg 5.5785) (1314.79 im/s)\n",
            "[TRAIN] epoch 9/10  observation 2000/14871 batch loss: 5.8105 (avg 5.5841) (1247.82 im/s)\n",
            "[TRAIN] epoch 9/10  observation 3000/14871 batch loss: 5.2520 (avg 5.5844) (1141.99 im/s)\n",
            "[TRAIN] epoch 9/10  observation 4000/14871 batch loss: 5.7286 (avg 5.5879) (1296.39 im/s)\n",
            "[TRAIN] epoch 9/10  observation 5000/14871 batch loss: 5.6703 (avg 5.5928) (1164.76 im/s)\n",
            "[TRAIN] epoch 9/10  observation 6000/14871 batch loss: 5.7791 (avg 5.5956) (1132.05 im/s)\n",
            "[TRAIN] epoch 9/10  observation 7000/14871 batch loss: 5.8627 (avg 5.5940) (1314.20 im/s)\n",
            "[TRAIN] epoch 9/10  observation 8000/14871 batch loss: 5.4483 (avg 5.5948) (1332.59 im/s)\n",
            "[TRAIN] epoch 9/10  observation 9000/14871 batch loss: 5.5932 (avg 5.5958) (1195.41 im/s)\n",
            "[TRAIN] epoch 9/10  observation 10000/14871 batch loss: 5.3987 (avg 5.5965) (1221.09 im/s)\n",
            "[TRAIN] epoch 9/10  observation 11000/14871 batch loss: 5.8755 (avg 5.5967) (1235.19 im/s)\n",
            "[TRAIN] epoch 9/10  observation 12000/14871 batch loss: 5.4831 (avg 5.5968) (1219.14 im/s)\n",
            "[TRAIN] epoch 9/10  observation 13000/14871 batch loss: 5.0752 (avg 5.5973) (1238.32 im/s)\n",
            "[TRAIN] epoch 9/10  observation 14000/14871 batch loss: 5.6187 (avg 5.5970) (1276.97 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [42:37<04:43, 283.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 validation: Recall@20: 0.5215, MRR@20: 0.2067 \n",
            "\n",
            "[TRAIN] epoch 10/10  observation 0/14871 batch loss: 5.2666 (avg 5.2666) (72.99 im/s)\n",
            "[TRAIN] epoch 10/10  observation 1000/14871 batch loss: 5.7699 (avg 5.5768) (1226.90 im/s)\n",
            "[TRAIN] epoch 10/10  observation 2000/14871 batch loss: 5.6046 (avg 5.5685) (1215.52 im/s)\n",
            "[TRAIN] epoch 10/10  observation 3000/14871 batch loss: 5.2650 (avg 5.5685) (1288.95 im/s)\n",
            "[TRAIN] epoch 10/10  observation 4000/14871 batch loss: 5.7716 (avg 5.5702) (1235.05 im/s)\n",
            "[TRAIN] epoch 10/10  observation 5000/14871 batch loss: 5.5118 (avg 5.5724) (1345.12 im/s)\n",
            "[TRAIN] epoch 10/10  observation 6000/14871 batch loss: 5.6683 (avg 5.5735) (1285.08 im/s)\n",
            "[TRAIN] epoch 10/10  observation 7000/14871 batch loss: 5.5198 (avg 5.5742) (1261.27 im/s)\n",
            "[TRAIN] epoch 10/10  observation 8000/14871 batch loss: 5.7424 (avg 5.5742) (1127.10 im/s)\n",
            "[TRAIN] epoch 10/10  observation 9000/14871 batch loss: 5.4600 (avg 5.5752) (1362.70 im/s)\n",
            "[TRAIN] epoch 10/10  observation 10000/14871 batch loss: 5.6930 (avg 5.5754) (1280.54 im/s)\n",
            "[TRAIN] epoch 10/10  observation 11000/14871 batch loss: 5.3101 (avg 5.5753) (1252.98 im/s)\n",
            "[TRAIN] epoch 10/10  observation 12000/14871 batch loss: 5.8736 (avg 5.5765) (1293.99 im/s)\n",
            "[TRAIN] epoch 10/10  observation 13000/14871 batch loss: 5.3327 (avg 5.5775) (1270.96 im/s)\n",
            "[TRAIN] epoch 10/10  observation 14000/14871 batch loss: 5.3922 (avg 5.5778) (1200.18 im/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [47:19<00:00, 283.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 validation: Recall@20: 0.5244, MRR@20: 0.2095 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.7. Dự báo\n",
        "Trước khi thực hiện dự báo thì ta sẽ cần phải load mô hình từ PATH đã lưu trước đó. Có 2 kiểu save mô hình chính trên pytorch đó là save toàn bộ mô hình và save các checkpoints. Nếu save toàn bộ mô hình sẽ buộc phải xác định các classes và cấu trúc thư mục lưu trữ mô hình nên thường dẫn tới xảy ra lỗi khi thay đổi project. Do đó save theo checkpoint thường được khuyến nghị, đối với bài toán này chúng ta cũng save mô hình theo checkpoint. Để load lại mô hình cũ ta thực hiện như sau:"
      ],
      "metadata": {
        "id": "ZxcwqF2sxct1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "PATH = 'latest_checkpoint.pth.tar'\n",
        "model = NARM(hidden_size = args['hidden_size'], n_items = 33751, embedding_dim = args['embed_dim'], n_layers=2, dropout=0.25).to(device)\n",
        "optimizer = optim.Adam(params = model.parameters(), lr=0.001)\n",
        "\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "epoch = checkpoint['epoch']\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRpXo1s2xeiZ",
        "outputId": "4265bf7f-b371-4414-a173-31cd3b44a134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NARM(\n",
              "  (embedding): Embedding(33751, 50, padding_idx=0)\n",
              "  (gru): GRU(50, 100, num_layers=2)\n",
              "  (emb_dropout): Dropout(p=0.25, inplace=False)\n",
              "  (a_1): Linear(in_features=100, out_features=100, bias=False)\n",
              "  (a_2): Linear(in_features=100, out_features=100, bias=False)\n",
              "  (v_t): Linear(in_features=100, out_features=1, bias=False)\n",
              "  (ct_dropout): Dropout(p=0.5, inplace=False)\n",
              "  (b): Linear(in_features=50, out_features=200, bias=False)\n",
              "  (sf): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lưu ý: Sau khi load xong model ta luôn phải chạy hàm model.eval() để kích hoạt các dropout và batchnormalization layer. Nếu không kết quả dự báo có thể dẫn tới sai lệch. Tiếp theo chúng ta sẽ sử dụng mô hình để dự báo cho một trường hợp cụ thể."
      ],
      "metadata": {
        "id": "inDVUL-6xgmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lựa chọn ngẫu nhiên một session trên test\n",
        "import numpy as np\n",
        "i = np.random.randint(0, len(test_index[0]))\n",
        "x = [test_index[0][i]]\n",
        "y = [test_index[1][i]]\n",
        "print('item indexes sequence input: ', x)\n",
        "print('item index next output: ', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIM_0aMMxjFI",
        "outputId": "5d136d2a-9ce2-4665-b1b0-17fe0f910b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item indexes sequence input:  [[30676, 32394, 29011]]\n",
            "item index next output:  [27150]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Khởi tạo test_loader để biến đổi dữ liệu session đưa vào mô hình\n",
        "test_data = RecSysDataset([x, y])\n",
        "test_loader = DataLoader(test_data, batch_size = args['batch_size'], shuffle = False, collate_fn = collate_fn)\n",
        "\n",
        "# Step 2: Dự báo các indice tiếp theo mà khách hàng có khả năng click\n",
        "def _preddict(loader, model):\n",
        "    model.eval()\n",
        "    recalls = []\n",
        "    mrrs = []\n",
        "    j = 1\n",
        "    with torch.no_grad():\n",
        "      for seq, target, lens in loader:\n",
        "        seq = seq.to(device)\n",
        "        target = target.to(device)\n",
        "        outputs = model(seq, lens)\n",
        "        logits = F.softmax(outputs, dim = 1)\n",
        "        _, indices = torch.topk(logits, 20, -1)\n",
        "        print('Is next clicked item in top 20 suggestions: ', (target in indices))\n",
        "        print('Top 20 next item indices suggested: ')\n",
        "    return indices\n",
        "\n",
        "_preddict(test_loader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31Njgyp3xnyR",
        "outputId": "d240560c-91c7-448a-e9f2-19976401bd77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 1\n",
            "--------------------------------------------------\n",
            "Is next clicked item in top 20 suggestions:  False\n",
            "Top 20 next item indices suggested: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[30675, 32346, 30690, 29010, 29008, 29056, 29024, 29020, 29043, 28984,\n",
              "         28562, 27093, 27098, 29027, 29011, 30693, 32401, 32358, 28985, 29048]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}